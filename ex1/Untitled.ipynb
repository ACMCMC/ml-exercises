{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "function J = computeCost(X, y, theta)\n",
    "%COMPUTECOST Compute cost for linear regression\n",
    "%   J = COMPUTECOST(X, y, theta) computes the cost of using theta as the\n",
    "%   parameter for linear regression to fit the data points in X and y\n",
    "\n",
    "% Initialize some useful values\n",
    "m = length(y); % number of training examples\n",
    "\n",
    "% You need to return the following variables correctly \n",
    "J = 0;\n",
    "\n",
    "% ====================== YOUR CODE HERE ======================\n",
    "% Instructions: Compute the cost of a particular choice of theta\n",
    "%               You should set J to the cost.\n",
    "\n",
    "mat_hip = X*theta;\n",
    "mat_dif = mat_hip-y;\n",
    "J = sum(mat_dif.^2)/(2*rows(X));\n",
    "\n",
    "\n",
    "% =========================================================================\n",
    "\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "function [theta, J_history] = gradientDescent(X, y, theta, alpha, num_iters)\n",
    "%GRADIENTDESCENT Performs gradient descent to learn theta\n",
    "%   theta = GRADIENTDESCENT(X, y, theta, alpha, num_iters) updates theta by \n",
    "%   taking num_iters gradient steps with learning rate alpha\n",
    "\n",
    "% Initialize some useful values\n",
    "m = length(y); % number of training examples\n",
    "J_history = zeros(num_iters, 1);\n",
    "\n",
    "disp(X(2));\n",
    "disp((alpha*sum((X*theta-y).*(X(2)))/m));\n",
    "\n",
    "for iter = 1:num_iters\n",
    "\n",
    "    % ====================== YOUR CODE HERE ======================\n",
    "    % Instructions: Perform a single gradient step on the parameter vector\n",
    "    %               theta. \n",
    "    %\n",
    "    % Hint: While debugging, it can be useful to print out the values\n",
    "    %       of the cost function (computeCost) and gradient here.\n",
    "    %\n",
    "\n",
    "    for j = 1:rows(theta)\n",
    "        theta(j) = theta(j) - alpha*sum((X*theta-y).*(X(j)))/m;\n",
    "        %disp(theta);\n",
    "        %printf('iteracion %d', j);\n",
    "    end\n",
    "\n",
    "\n",
    "\n",
    "    % ============================================================\n",
    "\n",
    "    % Save the cost J in every iteration    \n",
    "    J_history(iter) = computeCost(X, y, theta);\n",
    "\n",
    "end\n",
    "\n",
    "%disp(J_history);\n",
    "\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load('ex1data1.txt');\n",
    "X = data(:, 1); y = data(:, 2);\n",
    "m = length(y); % number of training examples\n",
    "X = [ones(m, 1), data(:,1)]; % Add a column of ones to x\n",
    "theta = zeros(2, 1); % initialize fitting parameters\n",
    "\n",
    "% Some gradient descent settings\n",
    "iterations = 1500;\n",
    "alpha = 0.01;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = length(y); % number of training examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "    for iter = 1:100\n",
    "    for j = 1:rows(theta)\n",
    "        theta(j) = theta(j) - alpha*sum((X*theta-y).*(X(:,j)))/m;\n",
    "        %disp(theta);\n",
    "        %printf('iteracion %d', j);\n",
    "    end\n",
    "    end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "theta =\n",
      "\n",
      "  -1.13217\n",
      "   0.91590\n",
      "\n"
     ]
    }
   ],
   "source": [
    "theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ans =\n",
      "\n",
      "    6.1101\n",
      "    5.5277\n",
      "    8.5186\n",
      "    7.0032\n",
      "    5.8598\n",
      "    8.3829\n",
      "    7.4764\n",
      "    8.5781\n",
      "    6.4862\n",
      "    5.0546\n",
      "    5.7107\n",
      "   14.1640\n",
      "    5.7340\n",
      "    8.4084\n",
      "    5.6407\n",
      "    5.3794\n",
      "    6.3654\n",
      "    5.1301\n",
      "    6.4296\n",
      "    7.0708\n",
      "    6.1891\n",
      "   20.2700\n",
      "    5.4901\n",
      "    6.3261\n",
      "    5.5649\n",
      "   18.9450\n",
      "   12.8280\n",
      "   10.9570\n",
      "   13.1760\n",
      "   22.2030\n",
      "    5.2524\n",
      "    6.5894\n",
      "    9.2482\n",
      "    5.8918\n",
      "    8.2111\n",
      "    7.9334\n",
      "    8.0959\n",
      "    5.6063\n",
      "   12.8360\n",
      "    6.3534\n",
      "    5.4069\n",
      "    6.8825\n",
      "   11.7080\n",
      "    5.7737\n",
      "    7.8247\n",
      "    7.0931\n",
      "    5.0702\n",
      "    5.8014\n",
      "   11.7000\n",
      "    5.5416\n",
      "    7.5402\n",
      "    5.3077\n",
      "    7.4239\n",
      "    7.6031\n",
      "    6.3328\n",
      "    6.3589\n",
      "    6.2742\n",
      "    5.6397\n",
      "    9.3102\n",
      "    9.4536\n",
      "    8.8254\n",
      "    5.1793\n",
      "   21.2790\n",
      "   14.9080\n",
      "   18.9590\n",
      "    7.2182\n",
      "    8.2951\n",
      "   10.2360\n",
      "    5.4994\n",
      "   20.3410\n",
      "   10.1360\n",
      "    7.3345\n",
      "    6.0062\n",
      "    7.2259\n",
      "    5.0269\n",
      "    6.5479\n",
      "    7.5386\n",
      "    5.0365\n",
      "   10.2740\n",
      "    5.1077\n",
      "    5.7292\n",
      "    5.1884\n",
      "    6.3557\n",
      "    9.7687\n",
      "    6.5159\n",
      "    8.5172\n",
      "    9.1802\n",
      "    6.0020\n",
      "    5.5204\n",
      "    5.0594\n",
      "    5.7077\n",
      "    7.6366\n",
      "    5.8707\n",
      "    5.3054\n",
      "    8.2934\n",
      "   13.3940\n",
      "    5.4369\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X(:,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Octave",
   "language": "octave",
   "name": "octave"
  },
  "language_info": {
   "file_extension": ".m",
   "help_links": [
    {
     "text": "GNU Octave",
     "url": "https://www.gnu.org/software/octave/support.html"
    },
    {
     "text": "Octave Kernel",
     "url": "https://github.com/Calysto/octave_kernel"
    },
    {
     "text": "MetaKernel Magics",
     "url": "https://metakernel.readthedocs.io/en/latest/source/README.html"
    }
   ],
   "mimetype": "text/x-octave",
   "name": "octave",
   "version": "5.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
